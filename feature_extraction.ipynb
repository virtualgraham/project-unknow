{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc, logfbank\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(signal):\n",
    "    plt.plot(list(signal))\n",
    "\n",
    "def plot_fft(fft):\n",
    "    data = list(fft)\n",
    "    Y, freq = data[0], data[1]\n",
    "    plt.plot(freq, Y)\n",
    "\n",
    "def plot_fbank(fbank):\n",
    "    plt.imshow(list(fbank),\n",
    "        cmap='hot', interpolation='nearest')\n",
    "\n",
    "def plot_mfccs(mfccs):\n",
    "    plt.imshow(list(mfccs),\n",
    "        cmap='hot', interpolation='nearest')\n",
    "\n",
    "def calc_fft(signal, rate):\n",
    "    n = len(signal)\n",
    "    freq = np.fft.rfftfreq(n, d=1/rate)\n",
    "    Y = abs(np.fft.rfft(signal)/n)\n",
    "    return (Y, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, signal = wavfile.read('data/FSDKaggle2018.audio_test/00326aa9.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_signal(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft = calc_fft(signal, rate)\n",
    "# plot_fft(fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank = logfbank(signal[:rate], rate, nfilt=26, nfft=1103).T\n",
    "# plot_fbank(bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = mfcc(signal[:rate], rate, numcep=13, nfilt=26, nfft=1102).T\n",
    "print(np.shape(mel))\n",
    "plot_mfccs(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Raw Value Histogram Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('data/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv', delimiter=',')\n",
    "tuples = [tuple(x) for x in df.values][:5]\n",
    "\n",
    "sample_count = 0\n",
    "mels = []\n",
    "\n",
    "# Encode all features\n",
    "for i in range(len(tuples)):\n",
    "    file = 'data/FSDKaggle2018.audio_test/' + tuples[i][0]\n",
    "    #print(file)\n",
    "    rate, signal = wavfile.read(file)\n",
    "    mel = mfcc(signal, rate, numcep=13, nfilt=26, nfft=1103)\n",
    "    sample_count += np.shape(mel)[0]\n",
    "    mels.append(mel)\n",
    "    \n",
    "n = sample_count * 13\n",
    "values = np.zeros(n)\n",
    "\n",
    "# create a sorted list of all feature values\n",
    "m = 0\n",
    "for i in range(len(tuples)):\n",
    "    \n",
    "    mel = mels[i]\n",
    "    \n",
    "    for k in range(np.shape(mel)[1]): # for each feature\n",
    "        \n",
    "        for j in range(np.shape(mel)[0]): # for each value\n",
    "            \n",
    "            values[m] = mels[i][j,k]\n",
    "            m += 1\n",
    "\n",
    "# for i in range(len(values)):\n",
    "#     print(get_bin(values[i]))\n",
    "    \n",
    "values = np.sort(values)\n",
    "\n",
    "print(np.shape(values))\n",
    "\n",
    "bin_count = 16\n",
    "bin_size = math.floor(n/bin_count)\n",
    "\n",
    "for i in range(bin_count):\n",
    "    print(i, bin_size, values[i*bin_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [\n",
    "-29.986096130739355, \n",
    "-19.195566310391943\n",
    ",-15.00016366240139\n",
    ",-10.998076289023\n",
    ",-6.748456575899296\n",
    ",-3.495771366216079\n",
    ",0.12159938915146001\n",
    ",3.2165856050505877\n",
    ",6.215759303055032\n",
    ",8.07164885810958\n",
    ",10.26041457182332\n",
    ",12.93044695246801\n",
    ",15.819326383946992\n",
    ",18.75778148814183\n",
    ",21.376683980339166]\n",
    "\n",
    "def get_bin(value):\n",
    "    for i in range(len(bins)):\n",
    "        if value < bins[i]:\n",
    "            return i\n",
    "    return len(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Delta Value Histogram Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('data/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv', delimiter=',')\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "\n",
    "sample_count = 0\n",
    "mels = []\n",
    "\n",
    "# Encode all features\n",
    "for i in range(len(tuples)):\n",
    "    file = 'data/FSDKaggle2018.audio_test/' + tuples[i][0]\n",
    "    #print(file)\n",
    "    rate, signal = wavfile.read(file)\n",
    "    mel = mfcc(signal, rate, numcep=13, nfilt=26, nfft=1103)\n",
    "    sample_count += np.shape(mel)[0]\n",
    "    mels.append(mel)\n",
    "    \n",
    "\n",
    "values_list = []\n",
    "\n",
    "# create a sorted list of all feature values\n",
    "\n",
    "last_v = float('nan')\n",
    "for i in range(len(tuples)):\n",
    "    \n",
    "    mel = mels[i]\n",
    "    \n",
    "    for k in range(np.shape(mel)[1]): # for each feature\n",
    "        \n",
    "        for j in range(np.shape(mel)[0]): # for each value\n",
    "            \n",
    "            v = mels[i][j,k]\n",
    "            \n",
    "            if not math.isnan(last_v):\n",
    "                delta = v - last_v\n",
    "                values_list.append(delta)\n",
    "#                 print(get_delta_bin(delta))\n",
    "                      \n",
    "            last_v = v\n",
    "\n",
    "values = np.sort(np.array(values_list))\n",
    "\n",
    "print(np.shape(values))\n",
    "\n",
    "bin_count = 16\n",
    "bin_size = math.floor(len(values)/bin_count)\n",
    "\n",
    "for i in range(bin_count):\n",
    "    print(i, bin_size, values[i*bin_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_bins = [\n",
    "-7.449361934437546,\n",
    "-4.959642638189663,\n",
    "-3.5063742894420997,\n",
    "-2.4518990367612536,\n",
    "-1.6107117954938024,\n",
    "-0.9037185755899212,\n",
    "-0.3158629551912462,\n",
    "-0.007594296904398945,\n",
    "0.3127680464479745,\n",
    "0.9294957576276741,\n",
    "1.644535296152842,\n",
    "2.487457184027898,\n",
    "3.5417890204116764,\n",
    "4.989806561955705,\n",
    "7.457516420676731]\n",
    "\n",
    "delta_zero_bin = 8\n",
    "\n",
    "def get_delta_bin(value):\n",
    "    for i in range(len(delta_bins)):\n",
    "        if value < delta_bins[i]:\n",
    "            return i\n",
    "    return len(delta_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Interval Histogram Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10761296,)\n",
      "0 672581 -1\n",
      "1 672581 1\n",
      "2 672581 2\n",
      "3 672581 3\n",
      "4 672581 5\n",
      "5 672581 7\n",
      "6 672581 10\n",
      "7 672581 13\n",
      "8 672581 16\n",
      "9 672581 20\n",
      "10 672581 25\n",
      "11 672581 31\n",
      "12 672581 38\n",
      "13 672581 48\n",
      "14 672581 63\n",
      "15 672581 89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "def get_interval(current_time, history_times, current_delta_bin):\n",
    "    \n",
    "    t = history_times[delta_zero_bin]\n",
    "\n",
    "    if t == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return current_time - t\n",
    "    \n",
    "    \n",
    "df = pd.read_csv('data/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv', delimiter=',')\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "\n",
    "sample_count = 0\n",
    "mels = []\n",
    "\n",
    "# Encode all features\n",
    "for i in range(len(tuples)):\n",
    "    file = 'data/FSDKaggle2018.audio_test/' + tuples[i][0]\n",
    "    rate, signal = wavfile.read(file)\n",
    "    mel = mfcc(signal, rate, numcep=13, nfilt=26, nfft=1103)\n",
    "    sample_count += np.shape(mel)[0]\n",
    "    mels.append(mel)\n",
    "    \n",
    "\n",
    "V = []\n",
    "\n",
    "for i in range(len(mels)): # for each sample\n",
    "    \n",
    "    mel = mels[i]\n",
    "    \n",
    "    for k in range(np.shape(mel)[1]): # for each feature\n",
    "        \n",
    "        history_times = np.full((16,), -1)\n",
    "        t = 0\n",
    "        last_delta_bin_1 = -1\n",
    "        last_delta_bin_2 = -1\n",
    "        \n",
    "        last_v_1 = float('nan')\n",
    "        \n",
    "        for j in range(np.shape(mel)[0]): # for each value\n",
    "            \n",
    "            next_v = mel[j,k]\n",
    "            current_v = last_v_1\n",
    "            current_delta_bin = last_delta_bin_1\n",
    "            last_delta_bin = last_delta_bin_2\n",
    "            \n",
    "            if not math.isnan(current_v):\n",
    "                next_delta = next_v - current_v   \n",
    "                next_delta_bin = get_delta_bin(next_delta)\n",
    "                \n",
    "                if current_delta_bin > -1:\n",
    "                    current_interval = get_interval(t, history_times, current_delta_bin)\n",
    "                    V.append(current_interval)\n",
    "     \n",
    "                    history_times[current_delta_bin] = t\n",
    "\n",
    "                    last_delta_bin_2 = current_delta_bin\n",
    "                    t+= 1\n",
    "                    \n",
    "                last_delta_bin_1 = next_delta_bin\n",
    "                \n",
    "            last_v_1 = next_v\n",
    "\n",
    "            \n",
    "V1 = np.array(V)\n",
    "V1 = np.sort(V1)\n",
    "\n",
    "print(np.shape(V1))\n",
    "\n",
    "bin_count = 16\n",
    "bin_size = math.floor(len(V1)/bin_count)\n",
    "\n",
    "for i in range(bin_count):\n",
    "    print(i, bin_size, V1[i*bin_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_bins = [\n",
    "1,\n",
    "2,\n",
    "3,\n",
    "5,\n",
    "7,\n",
    "10,\n",
    "13,\n",
    "16,\n",
    "20,\n",
    "25,\n",
    "31,\n",
    "38,\n",
    "48,\n",
    "63,\n",
    "89\n",
    "]\n",
    "\n",
    "\n",
    "def get_interval_bin(interval_value):\n",
    "    for i in reversed(range(len(interval_bins))):\n",
    "        if interval_value >= interval_bins[i]:\n",
    "            return i+1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Transition Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95., 124., 133., 118., 101.,  92.,  66.,  50.,  59.,  75.,  82.,\n",
       "        117., 104., 116., 108.,  91.],\n",
       "       [ 30.,  56.,  44.,  72.,  73.,  74.,  68.,  33.,  34.,  71.,  63.,\n",
       "         60.,  48.,  38.,  38.,  28.],\n",
       "       [ 31.,  39.,  50.,  46.,  55.,  60.,  54.,  22.,  26.,  55.,  46.,\n",
       "         63.,  46.,  48.,  41.,  17.],\n",
       "       [ 70.,  91.,  99.,  98., 111., 124.,  84.,  61.,  54., 102.,  98.,\n",
       "        106., 102., 101.,  65.,  50.],\n",
       "       [ 67.,  87., 101.,  81., 100.,  82.,  96.,  54.,  55., 102.,  90.,\n",
       "        106.,  94., 104.,  64.,  52.],\n",
       "       [ 74., 107., 101., 115., 112., 148., 128.,  58.,  74., 129., 118.,\n",
       "        116., 118., 117., 103.,  76.],\n",
       "       [ 73.,  95., 102.,  98., 113., 121., 104.,  42.,  59.,  98., 121.,\n",
       "        115., 111., 102.,  87.,  54.],\n",
       "       [ 66.,  83.,  99., 102.,  97.,  94.,  83.,  63.,  58.,  78., 109.,\n",
       "        107., 107.,  90.,  87.,  53.],\n",
       "       [ 91., 106., 129., 120., 116., 114.,  98.,  72.,  56.,  97., 115.,\n",
       "        108., 116.,  98., 113.,  63.],\n",
       "       [ 92., 125., 127., 129., 127.,  98., 115.,  62.,  62., 117., 113.,\n",
       "        134., 123., 132., 114.,  82.],\n",
       "       [ 93., 112., 133., 104., 127., 106., 112.,  50.,  47., 115., 112.,\n",
       "        108., 106., 112., 122.,  87.],\n",
       "       [ 80., 117., 120., 116., 139., 100., 100.,  51.,  55.,  98.,  92.,\n",
       "        123., 111., 131., 116.,  89.],\n",
       "       [ 91., 125., 125., 110., 110., 117., 102.,  44.,  54., 102., 117.,\n",
       "        115., 137., 115., 110.,  84.],\n",
       "       [132., 135., 116., 132., 105., 103., 104.,  60.,  45., 101., 112.,\n",
       "        114., 128., 119., 135.,  98.],\n",
       "       [120., 120., 134., 111., 109.,  98.,  90.,  49.,  43.,  97., 114.,\n",
       "        113., 126., 123., 134., 106.],\n",
       "       [130., 139., 119., 114., 100.,  82.,  53.,  41.,  49.,  85.,  79.,\n",
       "         85., 106., 112., 126., 130.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = np.zeros((13,16,16,16)) # feature, last_state, interval, current_state\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('data/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv', delimiter=',')\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "\n",
    "sample_count = 0\n",
    "mels = []\n",
    "\n",
    "# Encode all features\n",
    "for i in range(len(tuples)):\n",
    "    file = 'data/FSDKaggle2018.audio_test/' + tuples[i][0]\n",
    "    rate, signal = wavfile.read(file)\n",
    "    mel = mfcc(signal, rate, numcep=13, nfilt=26, nfft=1103)\n",
    "    sample_count += np.shape(mel)[0]\n",
    "    mels.append(mel)\n",
    "\n",
    "for i in range(len(mels)): # for each sample\n",
    "    \n",
    "    mel = mels[i]\n",
    "    \n",
    "    for k in range(np.shape(mel)[1]): # for each feature\n",
    "        \n",
    "        history_times = np.full((16,), -1)\n",
    "        t = 0\n",
    "        last_delta_bin_1 = -1\n",
    "        last_delta_bin_2 = -1\n",
    "        \n",
    "        last_v_1 = float('nan')\n",
    "        \n",
    "        for j in range(np.shape(mel)[0]): # for each value\n",
    "            \n",
    "            next_v = mel[j,k]\n",
    "            current_v = last_v_1\n",
    "            current_delta_bin = last_delta_bin_1\n",
    "            last_delta_bin = last_delta_bin_2\n",
    "            \n",
    "            if not math.isnan(current_v):\n",
    "                next_delta = next_v - current_v   \n",
    "                next_delta_bin = get_delta_bin(next_delta)\n",
    "                \n",
    "                if current_delta_bin > -1:\n",
    "                    current_interval = get_interval(t, history_times, current_delta_bin)\n",
    "                    current_interval_bin = get_interval_bin(current_interval)\n",
    "                    \n",
    "                    hist[k, current_delta_bin, current_interval_bin, next_delta_bin] = hist[k, current_delta_bin, current_interval_bin, next_delta_bin] + 1\n",
    "        \n",
    "                    history_times[current_delta_bin] = t\n",
    "\n",
    "                    last_delta_bin_2 = current_delta_bin\n",
    "                    t+= 1\n",
    "                    \n",
    "                last_delta_bin_1 = next_delta_bin\n",
    "                \n",
    "            last_v_1 = next_v\n",
    "            \n",
    "            \n",
    "\n",
    "hist[7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 890.,  496.,  365.,  288.,  215.,  184.,  174.,   84.,   69.,\n",
       "         166.,  191.,  170.,  181.,  222.,  179.,  235.],\n",
       "       [ 217.,  135.,  107.,   87.,   66.,   44.,   41.,   23.,   21.,\n",
       "          44.,   43.,   52.,   29.,   37.,   50.,   36.],\n",
       "       [ 179.,  167.,  124.,   64.,   80.,   50.,   55.,   28.,   25.,\n",
       "          43.,   53.,   46.,   59.,   55.,   67.,   43.],\n",
       "       [ 407.,  266.,  208.,  173.,  147.,  113.,   71.,   38.,   36.,\n",
       "          85.,   95.,  101.,   93.,   91.,  103.,   99.],\n",
       "       [ 377.,  263.,  197.,  182.,  155.,  102.,  109.,   34.,   42.,\n",
       "          95.,   72.,  113.,   85.,   87.,  114.,  100.],\n",
       "       [ 565.,  382.,  260.,  242.,  166.,  144.,  144.,   72.,   73.,\n",
       "         134.,  130.,  144.,  138.,  146.,  156.,  133.],\n",
       "       [ 508.,  352.,  279.,  225.,  173.,  146.,  132.,   62.,   56.,\n",
       "         116.,  122.,  144.,  122.,  116.,  130.,  116.],\n",
       "       [ 481.,  333.,  212.,  185.,  142.,  125.,  114.,   55.,   49.,\n",
       "         111.,  120.,  130.,  125.,  109.,  106.,  103.],\n",
       "       [ 579.,  400.,  292.,  244.,  204.,  148.,  126.,   78.,   66.,\n",
       "         125.,  121.,  136.,  133.,  141.,  160.,  146.],\n",
       "       [ 639.,  446.,  315.,  264.,  191.,  179.,  160.,   78.,   69.,\n",
       "         157.,  145.,  163.,  146.,  158.,  152.,  152.],\n",
       "       [ 657.,  488.,  348.,  241.,  209.,  178.,  145.,   68.,   86.,\n",
       "         133.,  135.,  154.,  158.,  164.,  172.,  149.],\n",
       "       [ 654.,  455.,  307.,  243.,  195.,  172.,  131.,   63.,   82.,\n",
       "         143.,  161.,  159.,  144.,  163.,  172.,  159.],\n",
       "       [ 703.,  502.,  329.,  254.,  220.,  199.,  150.,   99.,   75.,\n",
       "         139.,  160.,  172.,  159.,  197.,  185.,  188.],\n",
       "       [ 858.,  526.,  371.,  306.,  265.,  210.,  166.,  103.,   79.,\n",
       "         170.,  158.,  203.,  192.,  215.,  217.,  226.],\n",
       "       [ 834.,  514.,  350.,  285.,  233.,  179.,  161.,   89.,  103.,\n",
       "         152.,  160.,  168.,  161.,  223.,  226.,  218.],\n",
       "       [1099.,  585.,  417.,  239.,  239.,  200.,  164.,   95.,   75.,\n",
       "         174.,  152.,  187.,  179.,  178.,  223.,  289.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist[11,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
