# Machine learning model for unsupervised knowledge discovery

## Tentative Model Structure

* Input signals are divided using component analysis - There can be many input signals from many sources as well as multiple candidates of component signals for each input signal  

* Component signals are converted to sequences composed from a discreet but potentially countably infinate set of states 

* Pass all sequences to a large set of state transition models (STMs)

* Each STM will independatley consume each input sub-sequence

* STMs will compute a similarity metric which is an estimate of how likeley recent inputs are to have been generated by the current model. When similarity scores are high, the STM is said to be "activated".

* Model is designed to be stacked hierarchically. The state sequence inputs of a higher layer is a sequences of activated STMs from the lower layer


### Not worked out yet

* A graph is maintained to model spacial-temporal relations between STMs

* STM transition probabilites are conditional to relations in the graph. For example if symbol q is strongly correlated temporally with the symbol u then P(X(t+1) == u|X(t) == q) should be high






## Inital Research Goals

Given a large amount of varied input sequences, of an audio files for example, the STMs should each learn to model unique and different elements. What learning algorithim should be used to enable the STMs to differentiate themselfs to model novel inputs.

New STM is created to model input that does not strongly activate and existing STM highly

or 

New STMs are always being created to model the active sequence. The goal is how to delete redundant STMs. 

Use information 







