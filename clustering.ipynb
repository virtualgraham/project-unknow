{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc, logfbank\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "delta_bins = [\n",
    "-7.449361934437546,\n",
    "-4.959642638189663,\n",
    "-3.5063742894420997,\n",
    "-2.4518990367612536,\n",
    "-1.6107117954938024,\n",
    "-0.9037185755899212,\n",
    "-0.3158629551912462,\n",
    "-0.007594296904398945,\n",
    "0.3127680464479745,\n",
    "0.9294957576276741,\n",
    "1.644535296152842,\n",
    "2.487457184027898,\n",
    "3.5417890204116764,\n",
    "4.989806561955705,\n",
    "7.457516420676731\n",
    "]\n",
    "\n",
    "\n",
    "interval_bins = [\n",
    "1,\n",
    "2,\n",
    "3,\n",
    "5,\n",
    "7,\n",
    "10,\n",
    "13,\n",
    "16,\n",
    "20,\n",
    "25,\n",
    "31,\n",
    "38,\n",
    "48,\n",
    "63,\n",
    "89\n",
    "]\n",
    "\n",
    "\n",
    "delta_zero_bin = 8\n",
    "delta_bin_count = 16\n",
    "interval_bin_count = 16\n",
    "\n",
    "\n",
    "def get_delta_bin(value):\n",
    "    for i in range(len(delta_bins)):\n",
    "        if value < delta_bins[i]:\n",
    "            return i\n",
    "    return len(delta_bins)\n",
    "\n",
    "\n",
    "def get_interval_bin(interval_value):\n",
    "    for i in reversed(range(len(interval_bins))):\n",
    "        if interval_value >= interval_bins[i]:\n",
    "            return i+1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_interval(current_time, history_times):\n",
    "    t = history_times[delta_zero_bin]\n",
    "    if t == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return current_time - t\n",
    "    \n",
    "    \n",
    "def mels_from_tuples(tuples):\n",
    "    mels = []\n",
    "\n",
    "    # Encode all features\n",
    "    for i in range(len(tuples)):\n",
    "        file = 'data/FSDKaggle2018.audio_test/' + tuples[i][0]\n",
    "        rate, signal = wavfile.read(file)\n",
    "        mel = mfcc(signal, rate, numcep=13, nfilt=26, nfft=1103)\n",
    "        mels.append(mel)\n",
    "        \n",
    "    return mels\n",
    "\n",
    "\n",
    "def build_transition_histogram(tuples):\n",
    "    hist = np.zeros((13,delta_bin_count,interval_bin_count,delta_bin_count)) # feature, last_state, interval, current_state\n",
    "\n",
    "    mels = mels_from_tuples(tuples)\n",
    "\n",
    "    for i in range(len(mels)): # for each sample\n",
    "\n",
    "        mel = mels[i]\n",
    "\n",
    "        for k in range(np.shape(mel)[1]): # for each feature\n",
    "\n",
    "            history_times = np.full((delta_bin_count,), -1)\n",
    "            t = 0\n",
    "            last_delta_bin_1 = -1\n",
    "            last_delta_bin_2 = -1\n",
    "\n",
    "            last_v_1 = float('nan')\n",
    "\n",
    "            for j in range(np.shape(mel)[0]): # for each value\n",
    "\n",
    "                next_v = mel[j,k]\n",
    "                current_v = last_v_1\n",
    "                current_delta_bin = last_delta_bin_1\n",
    "                last_delta_bin = last_delta_bin_2\n",
    "\n",
    "                if not math.isnan(current_v):\n",
    "                    next_delta = next_v - current_v   \n",
    "                    next_delta_bin = get_delta_bin(next_delta)\n",
    "\n",
    "                    if current_delta_bin > -1:\n",
    "                        current_interval = get_interval(t, history_times)\n",
    "                        current_interval_bin = get_interval_bin(current_interval)\n",
    "\n",
    "                        ##########\n",
    "\n",
    "                        hist[k, current_delta_bin, current_interval_bin, next_delta_bin] += 1\n",
    "\n",
    "                        ##########\n",
    "\n",
    "                        history_times[current_delta_bin] = t\n",
    "\n",
    "                        last_delta_bin_2 = current_delta_bin\n",
    "                        t+= 1\n",
    "\n",
    "                    last_delta_bin_1 = next_delta_bin\n",
    "\n",
    "                last_v_1 = next_v\n",
    "                \n",
    "    return hist\n",
    "\n",
    "\n",
    "def remove_delta_condition(hist):\n",
    "    return np.sum(hist, 1)\n",
    "                  \n",
    "    \n",
    "def remove_interval_condition(hist):\n",
    "    return np.sum(hist, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "\n",
    "\n",
    "def extract_flat_feats_rand(len):\n",
    "    r = np.random.rand(len)\n",
    "    return np.divide(r, np.sum(r))\n",
    "\n",
    "\n",
    "def extract_flat_feats(hist):\n",
    "    reduced_hist = np.sum(hist, (1,2))\n",
    "    for j in range(13):\n",
    "        reduced_hist[j] = np.divide(reduced_hist[j], np.sum(reduced_hist[j]))\n",
    "    result = np.ndarray.flatten(reduced_hist)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cluster(tuples):\n",
    "    descriptor_index = hnswlib.Index(space = 'cosine', dim = 13*delta_bin_count) \n",
    "    descriptor_index.init_index(max_elements = 2000, ef_construction = 200, M = 48)\n",
    "    \n",
    "    descriptors = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(tuples)):\n",
    "        t = tuples[i]\n",
    "        hist = build_transition_histogram([t])\n",
    "        hists.append(hist)\n",
    "        descriptors.append(extract_flat_feats(hist))\n",
    "\n",
    "    descriptor_index.add_items(descriptors)\n",
    "    \n",
    "    return (descriptors, hists, descriptor_index)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv', delimiter=',')\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "\n",
    "descriptors, hists, descriptor_index = cluster(tuples)\n",
    "\n",
    "\n",
    "################\n",
    "\n",
    "# n = 3\n",
    "\n",
    "# knn = descriptor_index.knn_query(descriptors, k=1+n)\n",
    "    \n",
    "# same_class_count = 0.0\n",
    "    \n",
    "# for i in range(len(knn[0])):\n",
    "#     for k in range(n):\n",
    "#         j = knn[0][i,k+1]\n",
    "#         if tuples[i][1] == tuples[j][1]:\n",
    "#             same_class_count += 1.0\n",
    "                    \n",
    "# same_class_count/(n*len(tuples))\n",
    "\n",
    "################\n",
    "\n",
    "\n",
    "clustered_hists = []\n",
    "\n",
    "for i in range(len(tuples)):  \n",
    "    knn = descriptor_index.knn_query([descriptors[i]], k=250)[0][0]\n",
    "    clustered_hist = np.sum(np.array([hists[index] for index in knn]), (0,))\n",
    "    \n",
    "    # set all zero elements to one\n",
    "    clustered_hist = np.where(clustered_hist==0, 1, clustered_hist)\n",
    "    \n",
    "    # normalize, log probability\n",
    "    for j in range(13):\n",
    "        for k in range(delta_bin_count):\n",
    "            for l in range (interval_bin_count):\n",
    "                clustered_hist[j,k,l] = np.log(np.divide(clustered_hist[j,k,l], np.sum(clustered_hist[j,k,l])))\n",
    "        \n",
    "    clustered_hists.append(clustered_hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for every hist, find n nearest neighbors, element wise sum them all together, replace all zero entries with a value of one\n",
    "\n",
    "for test imput sequence calculate sequence likelyhood for every summed together histogram, check if the highest scoring one has the same category as the summed histograms original sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.72970145, -2.95651156, -2.22562405, -2.26336438, -2.95651156,\n",
       "        -2.57702194, -2.68824757, -3.12356565, -3.44201938, -2.81341072,\n",
       "        -2.68824757, -2.43041846, -2.7488722 , -2.68824757, -2.95651156,\n",
       "        -3.21887582],\n",
       "       [-4.90527478, -3.65251181, -3.40119738, -2.46292774, -2.55389952,\n",
       "        -2.07206143, -2.65398298, -2.95936463, -3.0334726 , -2.30258509,\n",
       "        -2.34032542, -2.7080502 , -2.37954613, -2.7080502 , -3.29583687,\n",
       "        -4.2121276 ],\n",
       "       [-4.26619482, -3.01343185, -2.76211742, -2.32028467, -2.35665231,\n",
       "        -2.76211742, -2.56144673, -3.01343185, -3.01343185, -2.43361336,\n",
       "        -2.65675691, -2.47443535, -2.56144673, -2.81927584, -2.94443898,\n",
       "        -4.55387689],\n",
       "       [-4.4288307 , -3.04253634, -2.72408261, -2.26934645, -2.30856716,\n",
       "        -2.41392768, -2.53171072, -3.58153284, -3.33021841, -2.63707123,\n",
       "        -2.37044257, -2.48292055, -2.55702852, -3.08509595, -2.9247533 ,\n",
       "        -4.27468002],\n",
       "       [-4.4091553 , -3.82136864, -2.58460601, -2.49223269, -2.55285731,\n",
       "        -2.16844561, -2.4076753 , -3.02286094, -3.24600449, -2.65129738,\n",
       "        -2.4076753 , -2.55285731, -2.72275635, -2.72275635, -3.12822146,\n",
       "        -3.71600812],\n",
       "       [-4.04830062, -2.98358989, -2.91689851, -2.41906008, -2.54422323,\n",
       "        -2.45906542, -2.399642  , -3.05504885, -3.35515344, -2.24001185,\n",
       "        -2.63731365, -2.54422323, -2.79553766, -2.7399678 , -2.82452519,\n",
       "        -4.55912625],\n",
       "       [-3.74754137, -3.28800904, -2.4947784 , -2.4947784 , -2.18939675,\n",
       "        -2.70608749, -2.73594046, -3.52439782, -3.0969538 , -2.4712479 ,\n",
       "        -2.4947784 , -2.38230041, -2.56888637, -2.70608749, -3.34207626,\n",
       "        -4.03522344],\n",
       "       [-4.17658266, -3.12676054, -2.5115749 , -2.65675691, -2.68850561,\n",
       "        -2.23067251, -2.62598525, -3.12676054, -3.23212105, -2.68850561,\n",
       "        -2.29385141, -2.31583032, -2.62598525, -3.03145036, -2.98699859,\n",
       "        -3.92526823],\n",
       "       [-4.01538152, -2.84531027, -2.57501994, -2.3207858 , -2.62908716,\n",
       "        -2.74687019, -2.62908716, -3.03455227, -3.12156364, -2.57501994,\n",
       "        -2.65725803, -2.54904445, -2.54904445, -2.49903403, -2.91676923,\n",
       "        -4.60316818],\n",
       "       [-3.54192504, -2.6664563 , -2.81598804, -2.69462718, -2.63905733,\n",
       "        -2.53640318, -2.56109579, -3.30553626, -3.25424297, -2.61238908,\n",
       "        -2.51230562, -2.39982764, -2.48877513, -2.81598804, -2.84877786,\n",
       "        -3.68502588],\n",
       "       [-3.8691155 , -2.99364677, -2.95282477, -2.53411444, -2.48282114,\n",
       "        -2.56078268, -2.61635254, -2.87586373, -3.08065814, -2.43403098,\n",
       "        -2.58818166, -2.58818166, -2.70596469, -2.50813895, -2.73771339,\n",
       "        -4.56226268],\n",
       "       [-3.7999735 , -3.15811962, -2.31836896, -2.41367914, -2.41367914,\n",
       "        -2.51903966, -3.10682632, -3.15811962, -3.01151614, -2.73526276,\n",
       "        -2.54721053, -2.60605103, -2.54721053, -2.88368277, -2.77035408,\n",
       "        -3.61765194],\n",
       "       [-3.52862041, -2.56720925, -2.83547323, -2.69237239, -2.51005083,\n",
       "        -2.62783387, -2.40469032, -3.20319801, -3.32098105, -2.62783387,\n",
       "        -2.40469032, -2.69237239, -2.43000812, -2.76136526, -3.20319801,\n",
       "        -3.6956745 ],\n",
       "       [-3.25583153, -3.04452244, -2.79320801, -2.42548323, -2.47812696,\n",
       "        -2.75684037, -2.50552594, -3.44998755, -3.0933126 , -2.37547281,\n",
       "        -2.65505767, -2.32784476, -2.79320801, -2.68784749, -3.04452244,\n",
       "        -3.8918203 ],\n",
       "       [-3.34510792, -2.97041447, -2.60750897, -2.30901598, -2.24649563,\n",
       "        -2.90978984, -3.03495299, -3.34510792, -3.17805383, -2.15948425,\n",
       "        -2.90978984, -2.65196073, -2.85263143, -2.69848075, -2.52412736,\n",
       "        -4.6443909 ],\n",
       "       [-3.66867675, -2.7131653 , -2.3877429 , -2.7131653 , -2.33367568,\n",
       "        -2.79320801, -2.57006446, -4.17950237, -3.48635519, -2.63905733,\n",
       "        -2.63905733, -2.57006446, -2.18707221, -2.63905733, -3.08089008,\n",
       "        -3.8918203 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_hists[8][8,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.20875, \"reduced_hist = np.sum(hist, (1,2)) cosine similarity\"\n",
    "\n",
    "0.20583333333333334, \"reduced_hist = np.sum(hist, (1,2))\"\n",
    "\n",
    "0.17958333333333334, \"reduced_hist = np.sum(hist, (0,1))\"\n",
    "\n",
    "0.17354166666666668, \"reduced_hist = np.sum(hist, (0,2))\"\n",
    "\n",
    "0.15166666666666667  \"reduced_hist[i, math.floor(k/4.0), math.floor(l/4.0)]\"\n",
    "\n",
    "0.14208333333333334, \"reduced_hist = np.sum(hist, (1,))\"\n",
    "\n",
    "0.10708333333333334, \"reduced_hist = np.sum(hist, (1,3))\"\n",
    "\n",
    "0.033541666666666664 \"extract_flat_feats_rand(208)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mel(mel):\n",
    "    \n",
    "    encoded = np.full((np.shape(mel)[1], np.shape(mel)[0], 4), -1)\n",
    "    \n",
    "    for k in range(np.shape(mel)[1]): # for each feature\n",
    "            history_times = np.full((delta_bin_count,), -1)\n",
    "            t = 0\n",
    "            last_delta_bin_1 = -1\n",
    "            last_delta_bin_2 = -1\n",
    "\n",
    "            last_v_1 = float('nan')\n",
    "            \n",
    "            for j in range(np.shape(mel)[0]): # np.shape(mel)[0] for each value\n",
    "\n",
    "                next_v = mel[j,k]\n",
    "                current_v = last_v_1\n",
    "                current_delta_bin = last_delta_bin_1\n",
    "                last_delta_bin = last_delta_bin_2\n",
    "\n",
    "                if not math.isnan(current_v):\n",
    "                    next_delta = next_v - current_v   \n",
    "                    next_delta_bin = get_delta_bin(next_delta)\n",
    "\n",
    "                    if current_delta_bin > -1:\n",
    "                        current_interval = get_interval(t, history_times)\n",
    "                        current_interval_bin = get_interval_bin(current_interval)\n",
    "                        \n",
    "                        #############\n",
    "                        \n",
    "                        encoded[k, j, 0] = k\n",
    "                        encoded[k, j, 1] = current_delta_bin\n",
    "                        encoded[k, j, 2] = current_interval_bin\n",
    "                        encoded[k, j, 3] = next_delta_bin\n",
    "                \n",
    "                        #############\n",
    "                        \n",
    "                        history_times[current_delta_bin] = t\n",
    "\n",
    "                        last_delta_bin_2 = current_delta_bin\n",
    "                        t+= 1\n",
    "\n",
    "                    last_delta_bin_1 = next_delta_bin\n",
    "\n",
    "                last_v_1 = next_v\n",
    "    \n",
    "    return encoded[:,2:,:].reshape((np.shape(mel)[0]-2) * np.shape(mel)[1], 4)\n",
    "\n",
    "\n",
    "def likelihood_hist(hist, clustered_hist):\n",
    "    return np.sum(np.multiply(hist, clustered_hist))\n",
    "\n",
    "\n",
    "def likelihood_mel(encoded_mel, clustered_hist):\n",
    "    p = 0.0\n",
    "    for k in encoded_mel:\n",
    "        p += clustered_hist[tuple(k)]    \n",
    "    return p\n",
    "\n",
    "\n",
    "def likeliest_hist(hist, clustered_hists, n):\n",
    "    l = np.zeros(len(clustered_hists))\n",
    "    \n",
    "    print(len(clustered_hists))\n",
    "    \n",
    "    for i in range(len(clustered_hists)):\n",
    "        if(i%200 == 0):\n",
    "            print(i)\n",
    "        l[i] = likelihood_hist(hist, clustered_hists[i])\n",
    "        \n",
    "    s = np.argsort(-l)[:n]\n",
    "    return (s, l[s])\n",
    "\n",
    "\n",
    "def likeliest_mel(mel, clustered_hists, n):\n",
    "    l = np.zeros(len(clustered_hists))\n",
    "    \n",
    "    print(len(clustered_hists))\n",
    "    \n",
    "    encoded_mel = encode_mel(mel)\n",
    "    \n",
    "    for i in range(len(clustered_hists)):\n",
    "        if(i%200 == 0):\n",
    "            print(i)\n",
    "        l[i] = likelihood_mel(encoded_mel, clustered_hists[i])\n",
    "        \n",
    "    s = np.argsort(-l)[:n]\n",
    "    return (s, l[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419, 13)\n",
      "1600\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1267, 1580, 1510,   59, 1531,  791,  627,  858, 1528,  228]),\n",
       " array([-13815.48370268, -13819.95080261, -13824.71646915, -13829.79670764,\n",
       "        -13830.2118661 , -13830.53680435, -13831.73751549, -13832.11319527,\n",
       "        -13834.71914204, -13834.71992995]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel = mels_from_tuples([tuples[89]])[0]\n",
    "# encoded_mel = encode_mel(mel[:100,:])\n",
    "print(np.shape(mel))\n",
    "likeliest_mel(mel, clustered_hists, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1029, 1246,  863,  959,  212, 1391,  523,  850,  657, 1161]),\n",
       " array([-6456.83595584, -6459.00697724, -6459.26115932, -6460.93123733,\n",
       "        -6461.73046159, -6462.37650453, -6462.71506957, -6463.22854251,\n",
       "        -6463.27241612, -6463.39803372]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likeliest_hist(hists[0], clustered_hists, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oboe'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harmonica'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples[1029][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oboe'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples[212][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
